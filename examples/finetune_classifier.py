"""Example of fine-tuning a TabPFN classifier using the FinetunedTabPFNClassifier wrapper.

Note: We recommend running the fine-tuning scripts on a CUDA-enabled GPU, as full
support for the Apple Silicon (MPS) backend is still under development.
"""

import warnings

import numpy as np
import sklearn.datasets
import torch
from sklearn.metrics import log_loss, roc_auc_score
from sklearn.model_selection import train_test_split

from tabpfn import TabPFNClassifier
from tabpfn.finetuning.finetuned_classifier import (
    FinetunedTabPFNClassifier,
)

warnings.filterwarnings(
    "ignore",
    category=FutureWarning,
    module=r"google\.api_core\._python_version_support",
)

# =============================================================================
# Fine-tuning Configuration
# For details and more options see FinetunedTabPFNClassifier
# =============================================================================

# Training hyperparameters
NUM_EPOCHS = 30
LEARNING_RATE = 2e-5

# Data sampling configuration (dataset dependent)
# the ratio of the total dataset to be used for validation during training
VALIDATION_SPLIT_RATIO = 0.1
# total context split into train/test
NUM_FINETUNE_CTX_PLUS_QUERY_SAMPLES = 10_000
# the following means 0.2*10_000=2_000 test samples are used in training
FINETUNE_CTX_QUERY_SPLIT_RATIO = 0.2
NUM_INFERENCE_SUBSAMPLE_SAMPLES = 50_000
# to reduce memory usage during training we can use activation checkpointing,
# may not be necessary for small datasets
USE_ACTIVATION_CHECKPOINTING = True

# Ensemble configuration
# number of estimators to use during finetuning
NUM_ESTIMATORS_FINETUNE = 2
# number of estimators to use during trian time validation
NUM_ESTIMATORS_VALIDATION = 2
# number of estimators to use during final inference
NUM_ESTIMATORS_FINAL_INFERENCE = 8

# Reproducibility
RANDOM_STATE = 0


def calculate_roc_auc(y_true: np.ndarray, y_pred_proba: np.ndarray) -> float:
    """Calculate ROC AUC with binary vs. multiclass handling."""
    if len(np.unique(y_true)) == 2:
        return roc_auc_score(
            y_true, y_pred_proba[:, 1]
        )  # pyright: ignore[reportReturnType]
    return roc_auc_score(
        y_true, y_pred_proba, multi_class="ovr"
    )  # pyright: ignore[reportReturnType]


def main() -> None:
    # We use the "Higgs" dataset (see https://www.openml.org/search?type=data&sort=runs&id=44129&status=active)
    # but only take a random subset of 100k samples for this example.
    data = sklearn.datasets.fetch_openml(data_id=44129, as_frame=True, parser="auto")
    _, X_all, _, y_all = train_test_split(
        data.data,
        data.target,
        test_size=100_000,
        random_state=RANDOM_STATE,
        stratify=data.target,
    )

    X_train, X_test, y_train, y_test = train_test_split(
        X_all, y_all, test_size=0.1, random_state=RANDOM_STATE, stratify=y_all
    )

    print(
        f"Loaded {len(X_train):,} samples for training and {len(X_test):,} samples for testing."
    )

    # 2. Initial model evaluation on test set
    inference_config = {
        "SUBSAMPLE_SAMPLES": NUM_INFERENCE_SUBSAMPLE_SAMPLES,
    }
    base_clf = TabPFNClassifier(
        device=[f"cuda:{i}" for i in range(torch.cuda.device_count())],
        n_estimators=NUM_ESTIMATORS_FINAL_INFERENCE,
        ignore_pretraining_limits=True,
        inference_config=inference_config,
    )
    base_clf.fit(X_train, y_train)

    base_pred_proba = base_clf.predict_proba(X_test)
    roc_auc = calculate_roc_auc(y_test, base_pred_proba)
    log_loss_score = log_loss(y_test, base_pred_proba)

    print(f"ðŸ“Š Default TabPFN Test ROC: {roc_auc:.4f}")
    print(f"ðŸ“Š Default TabPFN Test Log Loss: {log_loss_score:.4f}\n")

    # 3. Initialize and run fine-tuning
    print("--- 2. Initializing and Fitting Model ---\n")

    # Instantiate the wrapper with your desired hyperparameters
    finetuned_clf = FinetunedTabPFNClassifier(
        device="cuda" if torch.cuda.is_available() else "cpu",
        epochs=NUM_EPOCHS,
        learning_rate=LEARNING_RATE,
        validation_split_ratio=VALIDATION_SPLIT_RATIO,
        n_finetune_ctx_plus_query_samples=NUM_FINETUNE_CTX_PLUS_QUERY_SAMPLES,
        finetune_ctx_query_split_ratio=FINETUNE_CTX_QUERY_SPLIT_RATIO,
        n_inference_subsample_samples=NUM_INFERENCE_SUBSAMPLE_SAMPLES,
        random_state=RANDOM_STATE,
        n_estimators_finetune=NUM_ESTIMATORS_FINETUNE,
        n_estimators_validation=NUM_ESTIMATORS_VALIDATION,
        n_estimators_final_inference=NUM_ESTIMATORS_FINAL_INFERENCE,
        use_activation_checkpointing=USE_ACTIVATION_CHECKPOINTING,
    )

    # 4. Call .fit() to start the fine-tuning process on the training data
    finetuned_clf.fit(X_train, y_train)
    print("\n")

    # 5. Evaluate the fine-tuned model
    print("--- 3. Evaluating Model on Held-out Test Set ---\n")
    y_pred_proba = finetuned_clf.predict_proba(X_test)

    roc_auc = calculate_roc_auc(y_test, y_pred_proba)
    loss = log_loss(y_test, y_pred_proba)

    print(f"ðŸ“Š Finetuned TabPFN Test ROC: {roc_auc:.4f}")
    print(f"ðŸ“Š Finetuned TabPFN Test Log Loss: {loss:.4f}")


if __name__ == "__main__":
    main()
